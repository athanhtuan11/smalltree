import json
import logging
import time  # Move to top for faster import
import hashlib  # For caching
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from config import Config

# Simple in-memory cache for speed
_menu_cache = {}

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GeminiService:
    def __init__(self, api_key=None):
        """
        Initialize Gemini service
        """
        try:
            # Debug API key loading
            if api_key:
                print(f"üîß [DEBUG] Using provided API key")
                self.api_key = api_key
            else:
                api_key_from_config = getattr(Config, 'GEMINI_API_KEY', None)
                print(f"üîë [DEBUG] Gemini API key from config: {api_key_from_config[:10] if api_key_from_config else None}...")
                
                if not api_key_from_config:
                    # Hardcoded API key for testing - temporary measure
                    print(f"üîß [DEBUG] Using hardcoded API key for testing")
                    api_key_from_config = "AIzaSyC5F9JQiQJUQcQQWm9Qcy_ZGOzqZz_Bfeg"
                    
                self.api_key = api_key_from_config
            
            if self.api_key:
                genai.configure(api_key=self.api_key)
                
                # Use Gemini Pro model - try multiple versions for compatibility
                try:
                    self.model = genai.GenerativeModel(
                        model_name="gemini-1.5-pro",  # Stable Pro model
                        safety_settings={
                            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                        }
                    )
                    print(f"üöÄ Gemini service initialized with STABLE PRO model: gemini-1.5-pro")
                except Exception as model_error:
                    print(f"‚ö†Ô∏è Pro model failed, falling back to Flash: {model_error}")
                    self.model = genai.GenerativeModel(
                        model_name="gemini-1.5-flash",
                        safety_settings={
                            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                        }
                    )
                    print(f"‚úÖ Fallback to Flash model successful")
                logger.info("Gemini service initialized successfully")
            else:
                print("‚ö†Ô∏è Gemini API key not configured")
                logger.warning("Gemini API key not configured")
                self.model = None
                
        except Exception as e:
            logger.error(f"Failed to initialize Gemini service: {e}")
            self.model = None

    def is_configured(self):
        """Check if Gemini service is properly configured"""
        return self.model is not None

    def init_app(self, app):
        """Initialize with Flask app (for compatibility)"""
        pass

    def calculate_meal_count(self, available_ingredients):
        """
        Calculate number of meals based on available ingredients
        Enhanced logic for better variation
        """
        if not available_ingredients or available_ingredients.strip() == "":
            return 3  # Default if no ingredients specified
            
        # Count ingredients by splitting on comma and filtering non-empty
        ingredients = [x.strip() for x in available_ingredients.split(',') if x.strip()]
        ingredient_count = len(ingredients)
        
        print(f"üßÆ [DEBUG] Ingredient count: {ingredient_count}")
        
        # Smart calculation based on ingredient diversity
        if ingredient_count <= 3:
            return 2  # Few ingredients = fewer but focused meals
        elif ingredient_count <= 6:
            return 3  # Medium ingredients = moderate variety  
        elif ingredient_count <= 9:
            return 4  # Many ingredients = good variety
        else:
            return 5  # Lots of ingredients = maximum variety

    def generate_menu_suggestions(self, age_group=None, available_ingredients=None, special_requirements=None, 
                                age_months=None, dietary_preferences=None, menu_prompt=None):
        """
        Generate menu suggestions using Gemini AI with dynamic meal counting
        Supports both new (age_group) and legacy (age_months) signatures
        """
        if not self.is_configured():
            logger.error("Gemini service not configured")
            raise Exception("Gemini API ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh")
        
        # Handle legacy parameters
        if age_months is not None:
            # Convert age_months to age_group
            if age_months <= 12:
                age_group = "6-12 th√°ng"
            elif age_months <= 24:
                age_group = "1-2 tu·ªïi"
            elif age_months <= 36:
                age_group = "2-3 tu·ªïi"
            elif age_months <= 48:
                age_group = "3-4 tu·ªïi"
            else:
                age_group = "4-5 tu·ªïi"
        
        if dietary_preferences is not None:
            special_requirements = dietary_preferences
            
        # Ensure we have age_group
        if age_group is None:
            age_group = "2-3 tu·ªïi"  # Default

        # Calculate dynamic meal count
        num_meals = self.calculate_meal_count(available_ingredients)
        print(f"üìä [DEBUG] Expected meals count: {num_meals}")

        ingredients_text = available_ingredients if available_ingredients else "kh√¥ng c√≥ nguy√™n li·ªáu c·ª• th·ªÉ"
        requirements_text = special_requirements if special_requirements else "kh√¥ng c√≥ y√™u c·∫ßu ƒë·∫∑c bi·ªát"

        print(f"ü§ñ [DEBUG] Calling Gemini AI for {age_group}, ingredients: {ingredients_text[:50]}...")

        # Cache key for avoiding duplicate calls
        cache_key = hashlib.md5(f"{age_group}_{ingredients_text}_{requirements_text}".encode()).hexdigest()
        if cache_key in _menu_cache:
            print(f"‚ö° [CACHE HIT] Returning cached result")
            return _menu_cache[cache_key]

        # N·∫øu c√≥ menu_prompt th√¨ d√πng lu√¥n prompt n√†y, kh√¥ng t·ª± t·∫°o prompt m·∫∑c ƒë·ªãnh
        if menu_prompt:
            prompt = menu_prompt
        else:
            # üöÄ GEMINI 2.5 PRO OPTIMIZED PROMPT - Chi ti·∫øt v√† c·ª• th·ªÉ h∆°n
            prompt = f"""T·∫°o th·ª±c ƒë∆°n tu·∫ßn c√¢n b·∫±ng dinh d∆∞·ª°ng cho tr·∫ª {age_group}.
Nguy√™n li·ªáu c√≥ s·∫µn: {ingredients_text}
Y√™u c·∫ßu ƒë·∫∑c bi·ªát: {requirements_text}

L∆∞u √Ω: T√™n m√≥n ƒÉn ph·∫£i C·ª§ TH·ªÇ v√† CHI TI·∫æT. V√≠ d·ª•:
- Thay v√¨ \"C∆°m th·ªãt rau\" ‚Üí \"C∆°m th·ªãt heo x√†o c·∫£i th·∫£o\"
- Thay v√¨ \"Ch√°o g√†\" ‚Üí \"Ch√°o g√† x√© phay v·ªõi c√† r·ªët\"
- Thay v√¨ \"Canh rau\" ‚Üí \"Canh b√≠ ƒë·ªè th·ªãt b·∫±m\"

Tr·∫£ v·ªÅ JSON format:
{{
    \"weekly_menu\": {{
        \"mon\": {{\"morning\": \"Ch√°o g√† x√© phay v·ªõi c√† r·ªët\", \"snack\": \"S·ªØa chua c√≥ ƒë∆∞·ªùng\", \"dessert\": \"Chu·ªëi nghi·ªÅn m·∫≠t ong\", \"lunch\": \"C∆°m th·ªãt b√≤ x√†o ƒë·∫≠u cove\", \"afternoon\": \"B√°nh quy s·ªØa dinh d∆∞·ª°ng\", \"lateafternoon\": \"S·ªØa t∆∞∆°i kh√¥ng ƒë∆∞·ªùng\"}},
        \"tue\": {{\"morning\": \"Ph·ªü b√≤ th√°i nh·ªè c√≥ rau th∆°m\", \"snack\": \"B√°nh crackers nguy√™n c√°m\", \"dessert\": \"Cam v·∫Øt t∆∞∆°i\", \"lunch\": \"C∆°m g√† lu·ªôc v·ªõi b√≠ ƒë·ªè\", \"afternoon\": \"Ch√® ƒë·∫≠u xanh n∆∞·ªõc c·ªët d·ª´a\", \"lateafternoon\": \"N∆∞·ªõc √©p t√°o\"}},
        \"wed\": {{\"morning\": \"Ch√°o th·ªãt heo b·∫±m rau c·∫£i\", \"snack\": \"K·∫πo d·∫ªo vitamin C\", \"dessert\": \"T√°o nghi·ªÅn c√≥ qu·∫ø\", \"lunch\": \"C∆°m c√° h·ªìi √°p ch·∫£o rau mu·ªëng\", \"afternoon\": \"B√°nh bao nh√¢n th·ªãt nh·ªè\", \"lateafternoon\": \"S·ªØa ƒë·∫≠u n√†nh\"}},
        \"thu\": {{\"morning\": \"B√∫n ri√™u cua ƒë·ªìng c√≥ rau\", \"snack\": \"B√°nh su kem nh·ªè\", \"dessert\": \"Nho t√°ch h·∫°t t∆∞∆°i\", \"lunch\": \"C∆°m s∆∞·ªùn non h·∫ßm khoai t√¢y\", \"afternoon\": \"Ch√® cung ƒë√¨nh h·∫°t sen\", \"lateafternoon\": \"N∆∞·ªõc l·ªçc\"}},
        \"fri\": {{\"morning\": \"Ch√°o t√¥m nghi·ªÅn v·ªõi b√≠ ng√¥\", \"snack\": \"Yogurt t·ª± nhi√™n\", \"dessert\": \"L√™ nghi·ªÅn c√≥ m·∫≠t ong\", \"lunch\": \"C∆°m g√† n∆∞·ªõng rau c·∫£i xanh\", \"afternoon\": \"B√°nh flan caramen\", \"lateafternoon\": \"S·ªØa ƒë·∫≠u n√†nh vani\"}},
        \"sat\": {{\"morning\": \"M√¨ g√† tom yum th√°i nh·ªè\", \"snack\": \"B√°nh quy y·∫øn m·∫°ch\", \"dessert\": \"D∆∞a h·∫•u c·∫Øt nh·ªè\", \"lunch\": \"C∆°m th·ªãt heo rim m·∫Øm rau lang\", \"afternoon\": \"Ch√® th√°i h·∫°t l·ª±u\", \"lateafternoon\": \"S·ªØa t∆∞∆°i c√≥ canxi\"}}
    }},
    \"total_meals\": 36,
    \"nutrition_notes\": \"Th·ª±c ƒë∆°n c√¢n b·∫±ng protein, vitamin, kho√°ng ch·∫•t ph√π h·ª£p ƒë·ªô tu·ªïi v·ªõi t√™n m√≥n c·ª• th·ªÉ\"
}}"""

        print(f"üöÄ [SPEED] Calling Gemini with {len(prompt)} chars prompt...")
        
        start_time = time.time()  # Use pre-imported time

        try:
            # Add timeout and better error handling
            print(f"‚è∞ [DEBUG] Starting Gemini API call...")
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=1000,  # Pro model can handle more efficiently
                    temperature=0.3,         # Slightly higher for better quality
                    top_p=0.9,              # Better coherence in Pro model
                    top_k=40                # More vocab options for Pro
                ),
                request_options={'timeout': 30}  # 30 second timeout
            )
            print(f"‚úÖ [DEBUG] Gemini API call completed")
            
            api_time = time.time() - start_time
            print(f"‚ö° [SPEED] Gemini API took {api_time:.2f} seconds")
            
            if response and response.text:
                response_text = response.text.strip()
                print(f"üìù [SPEED] Response: {len(response_text)} chars")
                print(f"üîç [DEBUG] First 200 chars: {response_text[:200]}...")
                
                # Fast JSON parsing - try direct first
                try:
                    result = json.loads(response_text)
                    print(f"‚úÖ [SPEED] Direct JSON parse successful")
                    # Cache successful result
                    _menu_cache[cache_key] = result
                    return result
                except json.JSONDecodeError as je:
                    print(f"‚ö†Ô∏è [DEBUG] JSON decode error: {je}")
                    # Quick cleanup only if direct fails
                    clean_text = response_text.replace('```json', '').replace('```', '').strip()
                    try:
                        result = json.loads(clean_text)
                        print(f"‚úÖ [SPEED] Cleaned JSON parse successful")
                        # Cache successful result
                        _menu_cache[cache_key] = result
                        return result
                    except json.JSONDecodeError as je2:
                        # No fallback - raise error for AI-only mode
                        print(f"‚ùå [ERROR] JSON parsing failed completely: {je2}")
                        print(f"üîç [DEBUG] Raw response: {response_text}")
                        raise Exception("Gemini AI tr·∫£ v·ªÅ d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá")
            else:
                print(f"‚ùå [ERROR] Gemini returned empty response")
                raise Exception("Gemini kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£")
                
        except Exception as e:
            api_time = time.time() - start_time
            print(f"‚ùå [ERROR] Gemini API failed after {api_time:.2f}s: {e}")
            print(f"üîç [DEBUG] Error type: {type(e).__name__}")
            print(f"üîç [DEBUG] Error details: {str(e)}")
            logger.error(f"Gemini menu generation failed: {e}")
            
            # Raise exception instead of fallback - user wants AI only
            if "quota" in str(e).lower():
                raise Exception("‚ùå Gemini API ƒë√£ h·∫øt quota. Vui l√≤ng:\n1. Ki·ªÉm tra Google AI Studio (https://aistudio.google.com/)\n2. T·∫°o API key m·ªõi\n3. C·∫≠p nh·∫≠t v√†o config.py")
            else:
                raise Exception(f"Gemini AI kh√¥ng th·ªÉ t·∫°o th·ª±c ƒë∆°n: {str(e)}")

    def _convert_to_weekly_format(self, legacy_result, age_group, available_ingredients):
        """Convert legacy meal format to weekly menu format"""
        meals = legacy_result.get('meals', [])
        
        # Create weekly menu structure
        days = ['mon', 'tue', 'wed', 'thu', 'fri', 'sat']
        slots = ['morning', 'snack', 'dessert', 'lunch', 'afternoon', 'lateafternoon']
        
        weekly_menu = {}
        meal_index = 0
        
        for day in days:
            weekly_menu[day] = {}
            for slot in slots:
                if meal_index < len(meals):
                    meal = meals[meal_index]
                    weekly_menu[day][slot] = f"{meal.get('name', 'M√≥n ƒÉn dinh d∆∞·ª°ng')} - {meal.get('description', '')}"
                    meal_index += 1
                else:
                    # No fallback - raise error for AI-only mode
                    raise Exception(f"‚ùå Gemini API ƒë√£ h·∫øt quota. Vui l√≤ng: 1. Ki·ªÉm tra Google AI Studio, 2. T·∫°o API key m·ªõi, 3. C·∫≠p nh·∫≠t v√†o config.py")
        
        return {
            "weekly_menu": weekly_menu,
            "nutrition_analysis": legacy_result.get('overall_nutrition_analysis', 'Th·ª±c ƒë∆°n c√¢n b·∫±ng dinh d∆∞·ª°ng'),
            "recommendations": legacy_result.get('recommendations', 'ƒê·∫£m b·∫£o v·ªá sinh th·ª±c ph·∫©m'),
            "total_meals": 36,
            "week_summary": f"Th·ª±c ƒë∆°n tu·∫ßn cho tr·∫ª {age_group}"
        }

# Create global instance
try:
    gemini_service = GeminiService()
except Exception as e:
    logger.error(f"Failed to create gemini_service instance: {e}")
    gemini_service = None
